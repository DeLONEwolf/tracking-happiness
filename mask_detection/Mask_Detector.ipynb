{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "import random\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detector Using Tensorflow and OpenCV/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of With mask vs Without Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With Mask:  690\n",
      "Without Mask:  686\n"
     ]
    }
   ],
   "source": [
    "print(\"With Mask: \",len(os.listdir('with_mask')))\n",
    "print(\"Without Mask: \",len(os.listdir('without_mask')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(SOURCE, TRAIN, TEST, SPLIT_SIZE):\n",
    "    proper_data = []\n",
    "    for img in os.listdir(SOURCE):\n",
    "        img_path = SOURCE + img\n",
    "        if(os.path.getsize(img_path)>0):\n",
    "            proper_data.append(img)\n",
    "        else:\n",
    "            print(\"Issue in the Image:\"+ img_path)\n",
    "            \n",
    "    training_size = int(len(proper_data)*SPLIT_SIZE)\n",
    "    shuffled_data = random.sample(proper_data, len(proper_data))\n",
    "    training_data = shuffled_data[:training_size]\n",
    "    testing_data = shuffled_data[training_size:]\n",
    "    #print(training_data)\n",
    "    for img in training_data:\n",
    "        temp_img = SOURCE + img\n",
    "        train_img = TRAIN + img\n",
    "        copyfile(temp_img, train_img)\n",
    "\n",
    "    for img in testing_data:\n",
    "        temp_img = SOURCE + img\n",
    "        test_img = TEST + img\n",
    "        copyfile(temp_img, test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "YES_Source = 'with_mask/'\n",
    "TRAINING_YES_Source = 'train/with_mask/'\n",
    "TESTING_YES_Source = 'test/with_mask/'\n",
    "NO_Source = 'without_mask/'\n",
    "TRAINING_NO_Source = 'train/without_mask/'\n",
    "TESTING_NO_Source = 'test/without_mask/'\n",
    "split_size = 0.8\n",
    "split_data(YES_Source, TRAINING_YES_Source, TESTING_YES_Source, split_size)\n",
    "split_data(NO_Source, TRAINING_NO_Source, TESTING_NO_Source, split_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training with mask:  732\n",
      "Number of training without mask:  734\n",
      "Number of testing with mask:  212\n",
      "Number of testing without mask:  216\n"
     ]
    }
   ],
   "source": [
    "print('Number of training with mask: ', len(os.listdir(TRAINING_YES_Source)))\n",
    "print('Number of training without mask: ', len(os.listdir(TRAINING_NO_Source)))\n",
    "print('Number of testing with mask: ', len(os.listdir(TESTING_YES_Source)))\n",
    "print('Number of testing without mask: ', len(os.listdir(TESTING_NO_Source)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating CNN Model using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "#Creating the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1465 images belonging to 2 classes.\n",
      "Found 428 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIR = 'train/'\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "train_generator = train_datagen.flow_from_directory(TRAIN_DIR,\n",
    "                                                    target_size = (150,150),\n",
    "                                                    class_mode='categorical',\n",
    "                                                    batch_size = 32)\n",
    "TEST_DIR = 'test/'\n",
    "test_datagen = ImageDataGenerator(rescale = 1/255.0)\n",
    "test_generator = test_datagen.flow_from_directory(TEST_DIR,\n",
    "                                                target_size = (150,150),\n",
    "                                                class_mode='categorical',\n",
    "                                                batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to get best weights used when monitored with validation loss\n",
    "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "46/46 [==============================] - 34s 742ms/step - loss: 0.5234 - acc: 0.7283 - val_loss: 0.3067 - val_acc: 0.8692\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 29s 627ms/step - loss: 0.4426 - acc: 0.7986 - val_loss: 0.1797 - val_acc: 0.9252\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 32s 691ms/step - loss: 0.3134 - acc: 0.8655 - val_loss: 0.1534 - val_acc: 0.9463\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 31s 685ms/step - loss: 0.3262 - acc: 0.8614 - val_loss: 0.1749 - val_acc: 0.9463\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 32s 702ms/step - loss: 0.2851 - acc: 0.8853 - val_loss: 0.1709 - val_acc: 0.9393\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 31s 681ms/step - loss: 0.2708 - acc: 0.8962 - val_loss: 0.1141 - val_acc: 0.9673\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 31s 680ms/step - loss: 0.2548 - acc: 0.8990 - val_loss: 0.1376 - val_acc: 0.9579\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 30s 648ms/step - loss: 0.2197 - acc: 0.9106 - val_loss: 0.0844 - val_acc: 0.9813\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 29s 624ms/step - loss: 0.1796 - acc: 0.9365 - val_loss: 0.0713 - val_acc: 0.9766\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 28s 619ms/step - loss: 0.1936 - acc: 0.9297 - val_loss: 0.0820 - val_acc: 0.9743\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 29s 633ms/step - loss: 0.1920 - acc: 0.9283 - val_loss: 0.0682 - val_acc: 0.9790\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 30s 644ms/step - loss: 0.1707 - acc: 0.9372 - val_loss: 0.0726 - val_acc: 0.9883\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 29s 623ms/step - loss: 0.1933 - acc: 0.9229 - val_loss: 0.0728 - val_acc: 0.9743\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 29s 625ms/step - loss: 0.1922 - acc: 0.9283 - val_loss: 0.0656 - val_acc: 0.9766\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 29s 631ms/step - loss: 0.1779 - acc: 0.9386 - val_loss: 0.0526 - val_acc: 0.9836\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 29s 634ms/step - loss: 0.1637 - acc: 0.9406 - val_loss: 0.0630 - val_acc: 0.9883\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 29s 637ms/step - loss: 0.1605 - acc: 0.9365 - val_loss: 0.0769 - val_acc: 0.9696\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 29s 626ms/step - loss: 0.1542 - acc: 0.9433 - val_loss: 0.0364 - val_acc: 0.9907\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 29s 629ms/step - loss: 0.1245 - acc: 0.9597 - val_loss: 0.0293 - val_acc: 0.9930\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 29s 628ms/step - loss: 0.1207 - acc: 0.9556 - val_loss: 0.0409 - val_acc: 0.9953\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 29s 626ms/step - loss: 0.1128 - acc: 0.9570 - val_loss: 0.0249 - val_acc: 0.9907\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 29s 621ms/step - loss: 0.1282 - acc: 0.9522 - val_loss: 0.0283 - val_acc: 0.9907\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 29s 624ms/step - loss: 0.1295 - acc: 0.9563 - val_loss: 0.0296 - val_acc: 0.9860\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 29s 635ms/step - loss: 0.0985 - acc: 0.9618 - val_loss: 0.0224 - val_acc: 0.9930\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 29s 632ms/step - loss: 0.1039 - acc: 0.9625 - val_loss: 0.0912 - val_acc: 0.9673\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 29s 622ms/step - loss: 0.1690 - acc: 0.9386 - val_loss: 0.0639 - val_acc: 0.9790\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 29s 626ms/step - loss: 0.1092 - acc: 0.9618 - val_loss: 0.0412 - val_acc: 0.9860\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 29s 636ms/step - loss: 0.1270 - acc: 0.9509 - val_loss: 0.0414 - val_acc: 0.9883\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 29s 633ms/step - loss: 0.1117 - acc: 0.9652 - val_loss: 0.0275 - val_acc: 0.9930\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 29s 624ms/step - loss: 0.1039 - acc: 0.9638 - val_loss: 0.0332 - val_acc: 0.9930\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                             epochs = 30,\n",
    "                             validation_data=test_generator,\n",
    "                             callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Remove the commented Code lines to save your Video'''\n",
    "\n",
    "labels = {0:'No Mask Detected, You are Unsafe wear your mask please!',1:'Mask On, You are Amazing!'}\n",
    "color = {0:(0,0,255), 1:(255,0,0)}\n",
    "\n",
    "webcam1 = cv2.VideoCapture(0)\n",
    "\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "#fourcc = cv2.VideoWriter_fourcc(*'ADV1')\n",
    "#out = cv2.VideoWriter('lol.mp4', fourcc, 25, (640,480))\n",
    "while webcam1.isOpened():\n",
    "    _, frame = webcam1.read()\n",
    "    frame = cv2.flip(frame, 1, 1)\n",
    "    faces = classifier.detectMultiScale(frame, 1.1, 4)\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        #cv2.rectangle(frame, (x,y), (x+w, y+h), (255,0,0), 3)\n",
    "        face_data = frame[y:y+h, x:x+w]\n",
    "        resize_data = cv2.resize(face_data, (150,150))\n",
    "        resize_data = resize_data/255.0\n",
    "        final_data = np.expand_dims(resize_data, axis = 0)\n",
    "        prediction = model.predict(final_data)\n",
    "        \n",
    "        binary_answer = np.argmax(prediction,axis=1)[0]\n",
    "        \n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), color[binary_answer], 3)\n",
    "        cv2.rectangle(frame, (x,y-40), (x+w, y), color[binary_answer], -1)\n",
    "        cv2.putText(frame, labels[binary_answer], (x,y-10), cv2.FONT_HERSHEY_PLAIN, 1, (255,255,255), 1)\n",
    "    \n",
    "    cv2.imshow(\"Mask Detector\", frame)\n",
    "    #out.write(frame)\n",
    "        \n",
    "    if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "#out.release()\n",
    "webcam1.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model to file (JSON and H5 files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the model later on using this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
